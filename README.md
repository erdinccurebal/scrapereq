# ğŸ•¸ï¸ Scrapereq

<div align="center">
  <h3>A powerful and flexible web scraping API built with Express.js and Puppeteer</h3>
  <p>
    <img src="https://img.shields.io/badge/Express-5.1.0-000000?style=flat-square&logo=express" alt="Express.js" />
    <img src="https://img.shields.io/badge/Puppeteer-24.7.2-40B5A4?style=flat-square&logo=puppeteer" alt="Puppeteer" />
    <img src="https://img.shields.io/badge/Node.js-v20+-339933?style=flat-square&logo=node.js" alt="Node.js" />
    <img src="https://img.shields.io/badge/License-ISC-blue?style=flat-square" alt="License" />
  </p>
  <p>
    <a href="#-api-endpoints">API Documentation</a> â€¢
    <a href="#-installation">Installation</a> â€¢
    <a href="#-features">Features</a> â€¢
    <a href="#-tech-stack">Tech Stack</a>
  </p>
</div>

## ğŸ“‹ Overview

Scrapereq is a RESTful API service that allows you to perform web scraping operations by defining a series of steps executed by a headless browser. It provides a clean and secure way to extract data from websites with advanced features like proxy support, customizable scraping speeds, robust validation, and error handling.

## âœ¨ Features

### Core Capabilities

- **ğŸ”„ Step-Based Scraping**: Define your scraping workflow as a series of steps (navigate, click, wait, setViewport, etc.)
- **âš¡ Speed Control**: Multiple speed modes (TURBO, FAST, NORMAL, SLOW, SLOWEST, CRAWL, STEALTH)
- **ğŸ” Selector Support**: Extract data using CSS, XPath, or full page HTML selectors
- **âœ… Enhanced Validation**: Comprehensive request validation with clear error messages

### Security & Reliability

- **ğŸ” Built-in Security**: Basic authentication, helmet protection, and CORS configuration
- **ğŸŒ Enhanced Proxy Support**: Advanced proxy configuration with authentication and multiple proxy rotation
- **ğŸ”„ Error Handling**: Comprehensive error reporting with step indexing
- **ğŸ’ª Browser Resilience**: Automatic disconnection detection and resource management

### Advanced Features

- **ğŸ“¸ Screenshot Capabilities**: Capture success and error screenshots with configurable options
- **ğŸ“Š API Monitoring**: Detailed health check endpoint with system information
- **ğŸ“ Swagger Documentation**: Interactive API documentation with detailed request/response examples
- **ğŸ”§ System Controls**: Application shutdown and OS restart endpoints
- **ğŸ’¾ Persistent Storage**: Configurable screenshot directory for persistent storage across deployments
- **ğŸ§¹ Automatic Cleanup**: Automated cleanup of old screenshot files
- **ğŸ“ˆ Performance Metrics**: Track and analyze scraping performance with detailed metrics
- **ğŸ” Retry Mechanism**: Intelligent retry functionality for handling transient errors
- **ğŸ› ï¸ CLI Utilities**: User-friendly command-line interface for development and deployment

## ğŸ› ï¸ Tech Stack

- **ğŸ“¦ Node.js**: JavaScript runtime
- **ğŸš€ Express.js v5.1.0**: Web application framework
- **ğŸ¤– Puppeteer v24.7.2**: Headless Chrome browser automation
- **ğŸ§© Puppeteer-Extra v3.3.6**: Plugin system for Puppeteer
- **âºï¸ @puppeteer/replay v3.1.1**: Record and replay browser interactions
- **âœ… Joi v17.13.3**: Request validation
- **ğŸ“ Morgan**: HTTP request logging
- **ğŸ›¡ï¸ Helmet v8.1.0**: Security middleware
- **ğŸ“š Swagger-JSDoc v6.2.8**: API documentation generation
- **ğŸŒ Swagger-UI-Express v5.0.1**: Interactive API documentation
- **ğŸŒ CORS**: Cross-Origin Resource Sharing support
- **âš™ï¸ dotenv v16.5.0**: Environment configuration
- **ğŸ§ª Jest & Supertest**: Testing framework

## ğŸš€ Installation

1. **Clone the repository**:

   ```bash
   git clone https://github.com/yourusername/scrapereq.git
   cd scrapereq
   ```

2. **Install dependencies**:

   ```bash
   npm install
   ```

3. **Create a configuration file**:

   Create a `.env` file in the root directory based on the following template:

   ```env
   # Server Configuration
   PORT=3000
   HOST=localhost
   NODE_ENV=development
   WEB_ADDRESS=http://localhost:3000

   # Authentication
   AUTH_USERNAME=admin
   AUTH_PASSWORD=secretpassword

   # Puppeteer Configuration
   CHROME_PATH=/path/to/chrome # Optional custom Chrome path

   # File Storage
   TMP_DIR=/path/to/persistent/directory # Optional: defaults to ./tmp

   # Browser Concurrency
   MAX_CONCURRENT_BROWSERS=2 # Number of concurrent browser instances

   # Rate Limiting
   RATE_LIMIT_WINDOW_MS=900000 # 15 minutes in milliseconds
   RATE_LIMIT_MAX_REQUESTS=100 # Maximum requests per window
   ```

4. **Start the application**:
   ```bash
   npm start
   ```

## ğŸ”Œ API Endpoints

The API provides the following main endpoints:

### ğŸ” Health Check

```http
GET /api/app/health
```

Returns detailed system information and checks if all components are working correctly.

### ğŸ•¸ï¸ Scraper

```http
POST /api/scrape/start
```

Main endpoint for web scraping operations. Configure your scraping workflow with a detailed JSON structure.

#### Example Request:

<details>
<summary>ğŸ“‹ View example request body</summary>

```json
{
  "title": "Google Search Example",
  "speedMode": "NORMAL",
  "timeoutMode": "NORMAL",
  "responseType": "JSON",
  "errorScreenshot": true,
  "successScreenshot": true,
  "selectors": [
    {
      "key": "search_results",
      "type": "CSS",
      "value": "#search"
    },
    {
      "key": "page_title",
      "type": "CSS",
      "value": "title"
    }
  ],
  "steps": [
    {
      "type": "navigate",
      "url": "https://www.google.com"
    },
    {
      "type": "wait",
      "value": "1000"
    },
    {
      "type": "setViewport",
      "width": 1366,
      "height": 768
    }
  ]
}
```

</details>

### ğŸ“Š Performance Metrics

```http
GET /api/scrape/metrics
```

Returns performance metrics for all scraping operations.

```http
POST /api/scrape/metrics/reset
```

Resets all collected metrics.

### ğŸ”§ System Management

```http
POST /api/app/shutdown
```

Safely shuts down the application.

```http
POST /api/os/restart
```

Initiates an operating system restart (requires appropriate permissions).

## ğŸ“š Documentation

For complete API documentation, visit the Swagger UI endpoint after starting the application:

```
http://localhost:3000/api/docs
```

## ğŸ” Selector Types

Data can be extracted using different selector methods:

| Selector Type | Usage                                |
| ------------- | ------------------------------------ |
| `CSS`         | Standard CSS selectors               |
| `XPATH`       | XPath expressions                    |
| `FULL`        | Retrieves the full page HTML content |

## ğŸ”„ Response Types

The scraper supports multiple response formats:

| Type   | Description                                          |
| ------ | ---------------------------------------------------- |
| `JSON` | Returns structured JSON with data and metadata       |
| `RAW`  | Returns raw content from the first selector          |
| `NONE` | No response content (useful for headless operations) |

## ğŸ› ï¸ CLI Startup Options

The project includes several command-line utility scripts for easy startup and management:

```bash
# Start in development mode with auto-reload
npm run dev

# Start in production mode
npm run prod

# Run tests
npm test

# Lint code
npm run lint

# Fix linting issues
npm run lint:fix

# Format code with Prettier
npm run format

# Docker operations
npm run docker:build   # Build Docker image
npm run docker:run     # Run Docker container
npm run docker:start   # Start with Docker configuration
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ index.js                # Entry point
â”œâ”€â”€ start.js                # CLI startup script
â”œâ”€â”€ src/                    # Application source code
â”‚   â”œâ”€â”€ app.js              # Express app configuration
â”‚   â”œâ”€â”€ config.js           # Configuration module
â”‚   â”œâ”€â”€ constants.js        # Constants and enums
â”‚   â”œâ”€â”€ controllers/        # Request handlers
â”‚   â”œâ”€â”€ helpers/            # Helper functions
â”‚   â”œâ”€â”€ routes/             # API route definitions
â”‚   â””â”€â”€ utils/              # Utility middleware
â”œâ”€â”€ __tests__/              # Test files
â””â”€â”€ tmp/                    # Temporary files directory
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the ISC License - see the LICENSE file for details.

## ğŸ”„ Last Updated

May 4, 2025
